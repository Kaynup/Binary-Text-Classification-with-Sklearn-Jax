{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99eb449e-1052-489b-ac56-8debdc7643d0",
   "metadata": {},
   "source": [
    "# Loading processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9a2f6c-c11c-4fc6-90ba-a4d5e766a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ee9f6-5373-4d69-b967-809dd29f4908",
   "metadata": {},
   "source": [
    "## Logistic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e715af-6a74-41f8-9f15-76452194a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de58eab3-8d3c-4013-af7c-f64d68617df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-15 10:22:06 - Starting processing for all 3 datasets...\n",
      "2025-08-15 10:22:06 - \n",
      "=== Loading Dataset 1/3: dataset_001 ===\n",
      "2025-08-15 10:22:07 - Train set shape: (1341820, 10000), Test set shape: (236792, 10000)\n",
      "2025-08-15 10:22:07 - Starting RandomizedSearchCV (15 iterations)...\n",
      "2025-08-15 10:25:11 - RandomizedSearchCV completed.\n",
      "2025-08-15 10:25:11 - Best parameters found: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 700, 'C': 1}\n",
      "2025-08-15 10:25:11 - Best CV F1 score: 0.8072\n",
      "2025-08-15 10:25:12 - Test F1 Score: 0.8090\n",
      "2025-08-15 10:25:12 - Finished Dataset 1.\n",
      "--------------------------------------------------\n",
      "2025-08-15 10:25:12 - \n",
      "=== Loading Dataset 2/3: dataset_002 ===\n",
      "2025-08-15 10:25:14 - Train set shape: (1341820, 30000), Test set shape: (236792, 30000)\n",
      "2025-08-15 10:25:14 - Starting RandomizedSearchCV (15 iterations)...\n",
      "2025-08-15 10:28:36 - RandomizedSearchCV completed.\n",
      "2025-08-15 10:28:36 - Best parameters found: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 800, 'C': 1}\n",
      "2025-08-15 10:28:36 - Best CV F1 score: 0.8167\n",
      "2025-08-15 10:28:37 - Test F1 Score: 0.8185\n",
      "2025-08-15 10:28:37 - Finished Dataset 2.\n",
      "--------------------------------------------------\n",
      "2025-08-15 10:28:35 - \n",
      "=== Loading Dataset 3/3: dataset_003 ===\n",
      "2025-08-15 10:28:42 - Train set shape: (1341820, 80000), Test set shape: (236792, 80000)\n",
      "2025-08-15 10:28:42 - Starting RandomizedSearchCV (15 iterations)...\n",
      "2025-08-15 10:33:05 - RandomizedSearchCV completed.\n",
      "2025-08-15 10:33:05 - Best parameters found: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 800, 'C': 1}\n",
      "2025-08-15 10:33:05 - Best CV F1 score: 0.8218\n",
      "2025-08-15 10:33:05 - Test F1 Score: 0.8237\n",
      "2025-08-15 10:33:05 - Finished Dataset 3.\n",
      "--------------------------------------------------\n",
      "2025-08-15 10:33:06 - \n",
      "=== Summary of all datasets ===\n",
      "2025-08-15 10:33:06 - dataset_001: CV F1=0.8072, Test F1=0.8090, Best params={'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 700, 'C': 1}\n",
      "2025-08-15 10:33:06 - dataset_002: CV F1=0.8167, Test F1=0.8185, Best params={'solver': 'saga', 'penalty': 'l2', 'max_iter': 800, 'C': 1}\n",
      "2025-08-15 10:33:06 - dataset_003: CV F1=0.8218, Test F1=0.8237, Best params={'solver': 'saga', 'penalty': 'l2', 'max_iter': 800, 'C': 1}\n",
      "2025-08-15 10:33:06 - \n",
      "=== Best Dataset Overall ===\n",
      "2025-08-15 10:33:06 - Dataset ID: dataset_003 (Dataset number: 3)\n",
      "2025-08-15 10:33:06 - Dataset Name: dataset_003\n",
      "2025-08-15 10:33:06 - Best Test F1 Score: 0.8237\n",
      "2025-08-15 10:33:06 - Best Hyperparameters: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 800, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "NUM_DATASETS = 3\n",
    "N_ITERATIONS = 15\n",
    "\n",
    "# --- Setup logging ---\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Console handler (stdout)\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# File handler (write logs to file)\n",
    "file_handler = logging.FileHandler('process_log.txt', mode='w')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Log format with timestamps\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "console_handler.setFormatter(formatter)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Add handlers to logger\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# --- Dataset IDs ---\n",
    "all_indices = list(range(1, NUM_DATASETS + 1))\n",
    "config_ids = [f'dataset_{str(i).zfill(3)}' for i in all_indices]\n",
    "logger.info(f\"Starting processing for all {len(all_indices)} datasets...\")\n",
    "\n",
    "# --- Hyperparameter search space ---\n",
    "param_grid = {\n",
    "    'C': [0.5, 1, 5],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'max_iter': [600, 700, 800]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# --- Results tracking ---\n",
    "results = {}\n",
    "best_overall = {\n",
    "    'dataset_id': None,\n",
    "    'dataset_num': None,\n",
    "    'dataset_name': None,\n",
    "    'test_f1': -1,\n",
    "    'best_params': None\n",
    "}\n",
    "\n",
    "# --- Process datasets one-by-one ---\n",
    "for idx, cid in enumerate(config_ids, 1):\n",
    "    logger.info(f\"\\n=== Loading Dataset {idx}/{NUM_DATASETS}: {cid} ===\")\n",
    "    X_train, X_test, y_train, y_test, vectorizer, config = utils.load_processed(config_id=cid)\n",
    "\n",
    "    dataset_num = all_indices[idx - 1]\n",
    "    dataset_name = config.get('dataset_name', cid)\n",
    "    logger.info(f\"Train set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "\n",
    "    # Model & Search\n",
    "    lr = LogisticRegression()\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=lr,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=N_ITERATIONS,\n",
    "        scoring=f1_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=8,\n",
    "        random_state=42,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Starting RandomizedSearchCV ({N_ITERATIONS} iterations)...\")\n",
    "    random_search.fit(X_train, y_train)\n",
    "    logger.info(\"RandomizedSearchCV completed.\")\n",
    "    logger.info(f\"Best parameters found: {random_search.best_params_}\")\n",
    "    logger.info(f\"Best CV F1 score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    logger.info(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    results[cid] = {\n",
    "        'best_params': random_search.best_params_,\n",
    "        'cv_best_f1': random_search.best_score_,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    if test_f1 > best_overall['test_f1']:\n",
    "        best_overall.update({\n",
    "            'dataset_id': cid,\n",
    "            'dataset_num': dataset_num,\n",
    "            'dataset_name': dataset_name,\n",
    "            'test_f1': test_f1,\n",
    "            'best_params': random_search.best_params_\n",
    "        })\n",
    "\n",
    "    logger.info(f\"Finished Dataset {dataset_num}.\\n{'-'*50}\")\n",
    "\n",
    "    # --- Resource refresher ---\n",
    "    del X_train, X_test, y_train, y_test, vectorizer, config, lr, random_search, best_model, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "# --- Summary ---\n",
    "logger.info(\"\\n=== Summary of all datasets ===\")\n",
    "for cid, res in results.items():\n",
    "    logger.info(f\"{cid}: CV F1={res['cv_best_f1']:.4f}, Test F1={res['test_f1']:.4f}, Best params={res['best_params']}\")\n",
    "\n",
    "logger.info(\"\\n=== Best Dataset Overall ===\")\n",
    "logger.info(f\"Dataset ID: {best_overall['dataset_id']} (Dataset number: {best_overall['dataset_num']})\")\n",
    "logger.info(f\"Dataset Name: {best_overall['dataset_name']}\")\n",
    "logger.info(f\"Best Test F1 Score: {best_overall['test_f1']:.4f}\")\n",
    "logger.info(f\"Best Hyperparameters: {best_overall['best_params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cf4cd-c4fe-4965-b0be-b827246f21d3",
   "metadata": {},
   "source": [
    "## XGBoost - Sequential trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccc76d-c379-4a72-9a79-3d6daa43248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-30 07:03:28 - Starting processing for all 3 datasets...\n",
      "2025-09-30 07:03:28 - \n",
      "=== Loading Dataset 1/3: dataset_001 ===\n",
      "2025-09-30 07:03:29 - Train set shape: (1341820, 10000), Test set shape: (236792, 10000)\n",
      "2025-09-30 07:03:29 - Starting RandomizedSearchCV (15 iterations)...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Config ---\n",
    "NUM_DATASETS = 3\n",
    "N_ITERATIONS = 15\n",
    "\n",
    "# --- Setup logging ---\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Console handler (stdout)\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# File handler (write logs to file)\n",
    "file_handler = logging.FileHandler('process_log.txt', mode='w')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Log format with timestamps\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "console_handler.setFormatter(formatter)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Add handlers to logger\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# --- Dataset IDs ---\n",
    "all_indices = list(range(1, NUM_DATASETS + 1))\n",
    "config_ids = [f'dataset_{str(i).zfill(3)}' for i in all_indices]\n",
    "logger.info(f\"Starting processing for all {len(all_indices)} datasets...\")\n",
    "\n",
    "# --- Hyperparameter search space for XGBoost ---\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [0.5, 1, 2]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# --- Results tracking ---\n",
    "results = {}\n",
    "best_overall = {\n",
    "    'dataset_id': None,\n",
    "    'dataset_num': None,\n",
    "    'dataset_name': None,\n",
    "    'test_f1': -1,\n",
    "    'best_params': None\n",
    "}\n",
    "\n",
    "# --- Process datasets one-by-one ---\n",
    "for idx, cid in enumerate(config_ids, 1):\n",
    "    logger.info(f\"\\n=== Loading Dataset {idx}/{NUM_DATASETS}: {cid} ===\")\n",
    "    X_train, X_test, y_train, y_test, vectorizer, config = utils.load_processed(config_id=cid)\n",
    "\n",
    "    dataset_num = all_indices[idx - 1]\n",
    "    dataset_name = config.get('dataset_name', cid)\n",
    "    logger.info(f\"Train set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "\n",
    "    # Model & Search\n",
    "    xgb = XGBClassifier(\n",
    "        objective='binary:logistic', \n",
    "        eval_metric='logloss', \n",
    "        use_label_encoder=False, \n",
    "        n_jobs=8, \n",
    "        random_state=42\n",
    "    )\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=N_ITERATIONS,\n",
    "        scoring=f1_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=8,\n",
    "        random_state=42,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Starting RandomizedSearchCV ({N_ITERATIONS} iterations)...\")\n",
    "    random_search.fit(X_train, y_train)\n",
    "    logger.info(\"RandomizedSearchCV completed.\")\n",
    "    logger.info(f\"Best parameters found: {random_search.best_params_}\")\n",
    "    logger.info(f\"Best CV F1 score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    logger.info(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    results[cid] = {\n",
    "        'best_params': random_search.best_params_,\n",
    "        'cv_best_f1': random_search.best_score_,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "    if test_f1 > best_overall['test_f1']:\n",
    "        best_overall.update({\n",
    "            'dataset_id': cid,\n",
    "            'dataset_num': dataset_num,\n",
    "            'dataset_name': dataset_name,\n",
    "            'test_f1': test_f1,\n",
    "            'best_params': random_search.best_params_\n",
    "        })\n",
    "\n",
    "    logger.info(f\"Finished Dataset {dataset_num}.\\n{'-'*50}\")\n",
    "\n",
    "    # --- Resource refresher ---\n",
    "    del X_train, X_test, y_train, y_test, vectorizer, config, xgb, random_search, best_model, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "# --- Summary ---\n",
    "logger.info(\"\\n=== Summary of all datasets ===\")\n",
    "for cid, res in results.items():\n",
    "    logger.info(f\"{cid}: CV F1={res['cv_best_f1']:.4f}, Test F1={res['test_f1']:.4f}, Best params={res['best_params']}\")\n",
    "\n",
    "logger.info(\"\\n=== Best Dataset Overall ===\")\n",
    "logger.info(f\"Dataset ID: {best_overall['dataset_id']} (Dataset number: {best_overall['dataset_num']})\")\n",
    "logger.info(f\"Dataset Name: {best_overall['dataset_name']}\")\n",
    "logger.info(f\"Best Test F1 Score: {best_overall['test_f1']:.4f}\")\n",
    "logger.info(f\"Best Hyperparameters: {best_overall['best_params']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
